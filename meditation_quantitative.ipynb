{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8b967f",
   "metadata": {},
   "source": [
    "# Meditation App Impact on Sleep Analysis (N=4)\n",
    "\n",
    "**Project Goal:** To quantitatively test specific hypotheses about the effect of meditation apps on sleep latency and efficiency using data from a small user study (N=4).\n",
    "\n",
    "**Methodology:**\n",
    "1.  **Data Preparation:** Load data, calculate participant averages for key metrics (Sleep Latency, Sleep Efficiency) under different conditions (Baseline, Intervention, Guided Meditation, Music-based Meditation).\n",
    "2.  **Descriptive Statistics & Exploration:** Analyze the calculated averages and visualize trends.\n",
    "3.  **Inferential Statistics:** Use the Wilcoxon Signed-Rank test (non-parametric paired test appropriate for N=4) to test hypotheses about changes between conditions.\n",
    "4.  **Correlation Analysis (Optional):** Examine the relationship between objective sleep metrics and subjective self-reports using Spearman correlation.\n",
    "\n",
    "**Output:**\n",
    "- All textual results will be saved to `analysis_results.txt`.\n",
    "- All generated figures will be saved to the `figures/` directory.\n",
    "\n",
    "**Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65833522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text outputs will be saved to: analysis_results.txt\n",
      "Figures will be saved to: figures/\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from contextlib import redirect_stdout\n",
    "import io # To capture df.info()\n",
    "\n",
    "# Configure plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "# --- Output Setup ---\n",
    "output_txt_file = 'analysis_results.txt'\n",
    "figures_dir = 'figures'\n",
    "\n",
    "# Create figures directory if it doesn't exist\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "print(f\"Text outputs will be saved to: {output_txt_file}\")\n",
    "print(f\"Figures will be saved to: {figures_dir}/\")\n",
    "\n",
    "# Clear the output file at the start\n",
    "with open(output_txt_file, 'w') as f_out:\n",
    "    f_out.write(\"--- Analysis Results ---\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85151c",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Data Preparation\n",
    "\n",
    "Load the dataset and prepare it for analysis. Output from this section will be appended to the results file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f39ebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 1 processing complete. Results appended to analysis_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Append results to the file using context manager\n",
    "with open(output_txt_file, 'a') as f_out, redirect_stdout(f_out):\n",
    "    print(\"\\n--- Section 1: Setup & Data Preparation ---\")\n",
    "    \n",
    "    # Define file path \n",
    "    file_path = 'Participant Data.csv'\n",
    "    print(f\"\\nUsing data file: {file_path}\")\n",
    "    \n",
    "    # --- 1. Load Data ---\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"\\nSuccessfully loaded data.\")\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        \n",
    "        # Write head() output manually\n",
    "        f_out.write(\"\\nFirst 5 rows:\\n\")\n",
    "        f_out.write(df.head().to_string() + \"\\n\")\n",
    "        \n",
    "        # Write info() output manually using a string buffer\n",
    "        f_out.write(\"\\nData Info:\\n\")\n",
    "        # Capture info() output to a string buffer\n",
    "        buffer = io.StringIO()\n",
    "        df.info(buf=buffer)\n",
    "        info_output = buffer.getvalue()\n",
    "        f_out.write(info_output + \"\\n\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # If file not found, print to console and write to file, then raise error\n",
    "        error_msg = f\"Error: The file '{file_path}' was not found. Please ensure the CSV file is in the correct directory.\"\n",
    "        print(error_msg, file=sys.stderr) # Print error to console stderr\n",
    "        f_out.write(f\"\\n{error_msg}\\n\")\n",
    "        raise\n",
    "        \n",
    "    # --- 2. Define Conditions & Filter Data ---\n",
    "    print(\"\\n--- Filtering Data by Condition ---\")\n",
    "    baseline_df = df[df['Day'].isin([1, 2, 3, 4])].copy()\n",
    "    intervention_df = df[(df['Day'].isin([5, 6, 7, 8, 9, 10])) & (df['Meditation Used (Y/N)'] == 'Y')].copy()\n",
    "    guided_df = intervention_df[intervention_df['Meditation Type'] == 'Guided Voice'].copy()\n",
    "    music_df = intervention_df[intervention_df['Meditation Type'] == 'Music-based'].copy()\n",
    "\n",
    "    print(f\"Baseline nights count: {len(baseline_df)}\")\n",
    "    print(f\"Intervention nights (meditation used) count: {len(intervention_df)}\")\n",
    "    print(f\"Guided Voice nights count: {len(guided_df)}\")\n",
    "    print(f\"Music-based nights count: {len(music_df)}\")\n",
    "\n",
    "    # --- 3. Calculate Participant Averages per Condition ---\n",
    "    print(\"\\n--- Calculating Participant Averages ---\")\n",
    "    metrics_to_average = ['Sleep Latency (m)', 'Sleep Efficiency']\n",
    "    avg_baseline = baseline_df.groupby('Participant')[metrics_to_average].mean().reset_index()\n",
    "    avg_baseline = avg_baseline.rename(columns={'Sleep Latency (m)': 'Avg_Baseline_Latency', 'Sleep Efficiency': 'Avg_Baseline_Efficiency'})\n",
    "    avg_intervention = intervention_df.groupby('Participant')[metrics_to_average].mean().reset_index()\n",
    "    avg_intervention = avg_intervention.rename(columns={'Sleep Latency (m)': 'Avg_Intervention_Latency', 'Sleep Efficiency': 'Avg_Intervention_Efficiency'})\n",
    "    avg_guided = guided_df.groupby('Participant')['Sleep Latency (m)'].mean().reset_index()\n",
    "    avg_guided = avg_guided.rename(columns={'Sleep Latency (m)': 'Avg_Guided_Latency'})\n",
    "    avg_music = music_df.groupby('Participant')['Sleep Latency (m)'].mean().reset_index()\n",
    "    avg_music = avg_music.rename(columns={'Sleep Latency (m)': 'Avg_Music_Latency'})\n",
    "\n",
    "    # --- 4. Create Summary DataFrame ---\n",
    "    print(\"\\n--- Creating Summary DataFrame ---\")\n",
    "    summary_df = pd.merge(avg_baseline, avg_intervention, on='Participant', how='outer')\n",
    "    summary_df = pd.merge(summary_df, avg_guided, on='Participant', how='outer')\n",
    "    summary_df = pd.merge(summary_df, avg_music, on='Participant', how='outer')\n",
    "    summary_df = summary_df.set_index('Participant')\n",
    "\n",
    "    if summary_df.isnull().any().any():\n",
    "        print(\"\\nWarning: Missing values detected in summary_df:\")\n",
    "        print(summary_df.isnull().sum())\n",
    "        \n",
    "    # Write summary_df to file\n",
    "    f_out.write(\"\\n--- Participant Summary Averages ---\\n\")\n",
    "    f_out.write(summary_df.to_string() + \"\\n\")\n",
    "\n",
    "print(f\"Section 1 processing complete. Results appended to {output_txt_file}\")\n",
    "# We need summary_df and df for later sections\n",
    "global_summary_df = summary_df.copy()\n",
    "global_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9cfd95",
   "metadata": {},
   "source": [
    "## Section 2: Descriptive Statistics & Exploration\n",
    "\n",
    "Examine descriptive statistics and visualize trends based on the participant averages. Output appended to results file, figures saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc9ee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating and Saving Plots for Section 2 ---\n",
      "Saved box plot to: figures\\boxplots_participant_averages.png\n",
      "Saved paired plot to: figures\\pairedplots_participant_averages.png\n",
      "Section 2 processing complete. Results appended to analysis_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Use the global df copy\n",
    "summary_df = global_summary_df \n",
    "\n",
    "with open(output_txt_file, 'a') as f_out, redirect_stdout(f_out):\n",
    "    print(\"\\n\\n--- Section 2: Descriptive Statistics & Exploration ---\")\n",
    "    \n",
    "    # --- Descriptive Statistics for Participant Averages ---\n",
    "    print(\"\\n--- Descriptive Statistics for Participant Averages ---\")\n",
    "    f_out.write(summary_df.describe().to_string() + \"\\n\") # Write describe() output\n",
    "    \n",
    "    # --- Calculate Delta Scores ---\n",
    "    print(\"\\n--- Calculating Delta Scores (Changes) ---\")\n",
    "    summary_df['Latency_Delta (Intervention-Baseline)'] = summary_df['Avg_Intervention_Latency'] - summary_df['Avg_Baseline_Latency']\n",
    "    summary_df['Efficiency_Delta (Intervention-Baseline)'] = summary_df['Avg_Intervention_Efficiency'] - summary_df['Avg_Baseline_Efficiency']\n",
    "    summary_df['Latency_Delta (Guided-Music)'] = summary_df['Avg_Guided_Latency'] - summary_df['Avg_Music_Latency']\n",
    "    \n",
    "    print(\"\\n--- Descriptive Statistics for Delta Scores ---\")\n",
    "    delta_cols = [\n",
    "        'Latency_Delta (Intervention-Baseline)', \n",
    "        'Efficiency_Delta (Intervention-Baseline)', \n",
    "        'Latency_Delta (Guided-Music)'\n",
    "    ]\n",
    "    # Write delta describe() output\n",
    "    f_out.write(summary_df[delta_cols].describe().to_string() + \"\\n\")\n",
    "\n",
    "# --- Visualizations (Saving happens outside the redirect_stdout context) ---\n",
    "print(\"\\n--- Generating and Saving Plots for Section 2 ---\")\n",
    "\n",
    "# 1. Box Plots of Participant Averages\n",
    "fig_box, axes_box = plt.subplots(1, 3, figsize=(18, 5))\n",
    "sns.boxplot(data=summary_df[['Avg_Baseline_Latency', 'Avg_Intervention_Latency']], ax=axes_box[0])\n",
    "axes_box[0].set_title('Avg Latency: Baseline vs Intervention (N=4)')\n",
    "axes_box[0].set_ylabel('Average Sleep Latency (m)')\n",
    "sns.boxplot(data=summary_df[['Avg_Baseline_Efficiency', 'Avg_Intervention_Efficiency']], ax=axes_box[1])\n",
    "axes_box[1].set_title('Avg Efficiency: Baseline vs Intervention (N=4)')\n",
    "axes_box[1].set_ylabel('Average Sleep Efficiency (%)')\n",
    "sns.boxplot(data=summary_df[['Avg_Guided_Latency', 'Avg_Music_Latency']], ax=axes_box[2])\n",
    "axes_box[2].set_title('Avg Latency: Guided vs Music (N=4)')\n",
    "axes_box[2].set_ylabel('Average Sleep Latency (m)')\n",
    "fig_box.suptitle('Box Plots of Participant Averages Across Conditions', y=1.02)\n",
    "plt.tight_layout()\n",
    "boxplot_filename = os.path.join(figures_dir, 'boxplots_participant_averages.png')\n",
    "fig_box.savefig(boxplot_filename, bbox_inches='tight')\n",
    "plt.close(fig_box) # Close the figure to free memory\n",
    "print(f\"Saved box plot to: {boxplot_filename}\")\n",
    "\n",
    "# 2. Paired Before-After Plots\n",
    "fig_paired, axes_paired = plt.subplots(1, 3, figsize=(18, 5))\n",
    "participants = summary_df.index\n",
    "# Latency: Baseline vs Intervention\n",
    "axes_paired[0].plot([summary_df['Avg_Baseline_Latency'], summary_df['Avg_Intervention_Latency']], marker='o')\n",
    "axes_paired[0].set_xticks([0, 1]); axes_paired[0].set_xticklabels(['Baseline', 'Intervention'])\n",
    "axes_paired[0].set_ylabel('Average Sleep Latency (m)'); axes_paired[0].set_title('Paired Avg Latency: Baseline vs Intervention')\n",
    "for i, p in enumerate(participants): \n",
    "    axes_paired[0].text(0, summary_df['Avg_Baseline_Latency'].iloc[i], f' {p}', va='center'); axes_paired[0].text(1, summary_df['Avg_Intervention_Latency'].iloc[i], f' {p}', va='center')\n",
    "axes_paired[0].set_xlim(-0.2, 1.2)\n",
    "# Efficiency: Baseline vs Intervention\n",
    "axes_paired[1].plot([summary_df['Avg_Baseline_Efficiency'], summary_df['Avg_Intervention_Efficiency']], marker='o')\n",
    "axes_paired[1].set_xticks([0, 1]); axes_paired[1].set_xticklabels(['Baseline', 'Intervention'])\n",
    "axes_paired[1].set_ylabel('Average Sleep Efficiency (%)'); axes_paired[1].set_title('Paired Avg Efficiency: Baseline vs Intervention')\n",
    "for i, p in enumerate(participants): \n",
    "    axes_paired[1].text(0, summary_df['Avg_Baseline_Efficiency'].iloc[i], f' {p}', va='center'); axes_paired[1].text(1, summary_df['Avg_Intervention_Efficiency'].iloc[i], f' {p}', va='center')\n",
    "axes_paired[1].set_xlim(-0.2, 1.2)\n",
    "# Latency: Guided vs Music\n",
    "valid_comparison_h3 = summary_df[['Avg_Guided_Latency', 'Avg_Music_Latency']].dropna()\n",
    "if not valid_comparison_h3.empty:\n",
    "    axes_paired[2].plot([valid_comparison_h3['Avg_Music_Latency'], valid_comparison_h3['Avg_Guided_Latency']], marker='o')\n",
    "    axes_paired[2].set_xticks([0, 1]); axes_paired[2].set_xticklabels(['Music', 'Guided'])\n",
    "    axes_paired[2].set_ylabel('Average Sleep Latency (m)'); axes_paired[2].set_title(f'Paired Avg Latency: Music vs Guided (N={len(valid_comparison_h3)})')\n",
    "    for i, p in enumerate(valid_comparison_h3.index): \n",
    "        axes_paired[2].text(0, valid_comparison_h3['Avg_Music_Latency'].loc[p], f' {p}', va='center'); axes_paired[2].text(1, valid_comparison_h3['Avg_Guided_Latency'].loc[p], f' {p}', va='center')\n",
    "    axes_paired[2].set_xlim(-0.2, 1.2)\n",
    "else:\n",
    "    axes_paired[2].text(0.5, 0.5, 'Not enough paired data\\nfor Guided vs Music', ha='center', va='center'); axes_paired[2].set_title('Paired Avg Latency: Music vs Guided')\n",
    "fig_paired.suptitle('Paired Plots of Participant Averages Across Conditions', y=1.02)\n",
    "plt.tight_layout()\n",
    "pairedplot_filename = os.path.join(figures_dir, 'pairedplots_participant_averages.png')\n",
    "fig_paired.savefig(pairedplot_filename, bbox_inches='tight')\n",
    "plt.close(fig_paired) # Close the figure\n",
    "print(f\"Saved paired plot to: {pairedplot_filename}\")\n",
    "\n",
    "print(f\"Section 2 processing complete. Results appended to {output_txt_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197dcb1",
   "metadata": {},
   "source": [
    "## Section 3: Inferential Statistics - Hypothesis Testing\n",
    "\n",
    "Test hypotheses using Wilcoxon Signed-Rank test. Results appended to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fd5924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 3 processing complete. Results appended to analysis_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Use the global df copy\n",
    "summary_df = global_summary_df \n",
    "\n",
    "# Define functions first (outside the context manager)\n",
    "def calculate_effect_size_r(z_stat, n_pairs):\n",
    "    if n_pairs <= 0 or pd.isna(z_stat):\n",
    "        return np.nan\n",
    "    return z_stat / np.sqrt(n_pairs)\n",
    "\n",
    "# Modified function to work within redirect_stdout\n",
    "def run_wilcoxon_and_print(data1, data2, alternative, hypothesis_name, f_out):\n",
    "    f_out.write(f\"\\n--- Testing Hypothesis: {hypothesis_name} ---\\n\")\n",
    "    \n",
    "    combined = pd.DataFrame({'data1': data1, 'data2': data2}).dropna()\n",
    "    n_pairs = len(combined)\n",
    "    \n",
    "    if n_pairs < 4: \n",
    "        f_out.write(f\"Skipping test: Only {n_pairs} valid pairs found. Insufficient data.\\n\")\n",
    "        return\n",
    "        \n",
    "    d1 = combined['data1']\n",
    "    d2 = combined['data2']\n",
    "    \n",
    "    median1 = d1.median()\n",
    "    median2 = d2.median()\n",
    "    f_out.write(f\"Comparing medians: {median1:.2f} vs {median2:.2f}\\n\")\n",
    "    f_out.write(f\"Number of pairs (N): {n_pairs}\\n\")\n",
    "    \n",
    "    try:\n",
    "        stat, p_value = stats.wilcoxon(d1, d2, alternative=alternative, zero_method='pratt', correction=False)\n",
    "        \n",
    "        mu_W = n_pairs * (n_pairs + 1) / 4\n",
    "        sigma_W = np.sqrt(n_pairs * (n_pairs + 1) * (2 * n_pairs + 1) / 24)\n",
    "        \n",
    "        if sigma_W > 0:\n",
    "            z_stat_approx = (stat - mu_W) / sigma_W\n",
    "            effect_size_r = calculate_effect_size_r(z_stat_approx, n_pairs)\n",
    "            f_out.write(f\"Approximate Z-statistic: {z_stat_approx:.3f}\\n\")\n",
    "            f_out.write(f\"Effect Size (r = Z/sqrt(N)): {effect_size_r:.3f}\\n\")\n",
    "        else:\n",
    "            z_stat_approx = np.nan\n",
    "            effect_size_r = np.nan\n",
    "            f_out.write(\"Warning: Could not calculate Z-statistic approximation (sigma_W=0).\\n\")\n",
    "            f_out.write(f\"Approximate Z-statistic: {z_stat_approx}\\n\")\n",
    "            f_out.write(f\"Effect Size (r = Z/sqrt(N)): {effect_size_r}\\n\")\n",
    "\n",
    "        f_out.write(f\"Wilcoxon Test Statistic (W): {stat:.2f}\\n\")\n",
    "        f_out.write(f\"P-value (one-tailed, {alternative}): {p_value:.4f}\\n\")\n",
    "        \n",
    "        alpha = 0.05\n",
    "        if p_value < alpha:\n",
    "            f_out.write(f\"Conclusion: Reject H₀ (p < {alpha}). Evidence supports the alternative hypothesis.\\n\")\n",
    "        else:\n",
    "            f_out.write(f\"Conclusion: Fail to reject H₀ (p >= {alpha}). Insufficient evidence for the alternative hypothesis.\\n\")\n",
    "            \n",
    "    except ValueError as e:\n",
    "        f_out.write(f\"Could not perform Wilcoxon test: {e}\\n\")\n",
    "    except Exception as e:\n",
    "         f_out.write(f\"An unexpected error occurred during Wilcoxon test: {e}\\n\")\n",
    "\n",
    "# Now run the tests within the context manager\n",
    "with open(output_txt_file, 'a') as f_out:\n",
    "    # No redirect_stdout needed here as the function writes directly to f_out\n",
    "    f_out.write(\"\\n\\n--- Section 3: Inferential Statistics - Hypothesis Testing ---\\n\")\n",
    "    \n",
    "    # H1: Latency (Baseline vs Intervention)\n",
    "    run_wilcoxon_and_print(\n",
    "        summary_df['Avg_Baseline_Latency'], \n",
    "        summary_df['Avg_Intervention_Latency'], \n",
    "        alternative='greater', # H1: Intervention < Baseline --> Baseline > Intervention\n",
    "        hypothesis_name=\"H1: Latency (Baseline vs Intervention)\",\n",
    "        f_out=f_out\n",
    "    )\n",
    "    \n",
    "    # H2: Efficiency (Intervention vs Baseline)\n",
    "    run_wilcoxon_and_print(\n",
    "        summary_df['Avg_Intervention_Efficiency'], # Data 1\n",
    "        summary_df['Avg_Baseline_Efficiency'],    # Data 2\n",
    "        alternative='greater', # H1: Intervention > Baseline\n",
    "        hypothesis_name=\"H2: Efficiency (Intervention vs Baseline)\",\n",
    "        f_out=f_out\n",
    "    )\n",
    "    \n",
    "    # H3: Latency (Guided vs Music)\n",
    "    run_wilcoxon_and_print(\n",
    "        summary_df['Avg_Guided_Latency'], # Data 1\n",
    "        summary_df['Avg_Music_Latency'],  # Data 2\n",
    "        alternative='less', # H1: Guided < Music\n",
    "        hypothesis_name=\"H3: Latency (Guided vs Music)\",\n",
    "        f_out=f_out\n",
    "    )\n",
    "\n",
    "print(f\"Section 3 processing complete. Results appended to {output_txt_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c4304",
   "metadata": {},
   "source": [
    "## Section 4: Correlation Analysis\n",
    "\n",
    "Test relationship between objective and subjective metrics using Spearman correlation on per-night data. Results appended to file, figures saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b1277f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating and Saving Plots for Section 4 ---\n",
      "Saved histogram plot to: figures\\histograms_correlation_variables.png\n",
      "Section 4 processing complete. Results appended to analysis_results.txt\n",
      "\n",
      "--- Analysis Finished --- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the global df copy\n",
    "df = global_df\n",
    "\n",
    "with open(output_txt_file, 'a') as f_out, redirect_stdout(f_out):\n",
    "    print(\"\\n\\n--- Section 4: Correlation Analysis (Optional) ---\")\n",
    "    \n",
    "    print(\"\\n--- Preparing Data for Correlation ---\")\n",
    "    corr_df = df[['Sleep Latency (m)', 'Sleep Efficiency', 'Self-reported Sleep Quality (1-10)']].copy()\n",
    "    corr_df['Self-reported Sleep Quality (1-10)'] = pd.to_numeric(corr_df['Self-reported Sleep Quality (1-10)'], errors='coerce')\n",
    "    corr_df_cleaned = corr_df.dropna()\n",
    "    print(f\"Number of nights with complete data for correlation: {len(corr_df_cleaned)}\")\n",
    "\n",
    "    if len(corr_df_cleaned) < 3:\n",
    "        print(\"\\nInsufficient data points (<3) for meaningful descriptive statistics or correlation after handling NaNs.\")\n",
    "    else:\n",
    "        # --- Descriptive Statistics for Correlation Variables ---\n",
    "        print(\"\\n--- Descriptive Statistics for Variables in H4 (Per-Night Data) ---\")\n",
    "        f_out.write(corr_df_cleaned.describe().to_string() + \"\\n\") # Write describe() output\n",
    "        \n",
    "        # --- Spearman Correlation Tests ---\n",
    "        print(\"\\n--- Testing H4: Correlations (Objective vs. Subjective Quality) ---\")\n",
    "        alpha_corr = 0.05\n",
    "        \n",
    "        # Correlation 1: Latency vs. Subjective Quality\n",
    "        print(f\"\\nCorrelation: Sleep Latency vs. Self-reported Quality\")\n",
    "        rho_lat, p_lat = stats.spearmanr(corr_df_cleaned['Sleep Latency (m)'], corr_df_cleaned['Self-reported Sleep Quality (1-10)'], nan_policy='omit')\n",
    "        print(f\"Spearman's rho: {rho_lat:.3f}\")\n",
    "        print(f\"P-value: {p_lat:.4f}\")\n",
    "        if p_lat < alpha_corr:\n",
    "            print(f\"Conclusion: Significant correlation found (p < {alpha_corr}). Reject H₀.\")\n",
    "        else:\n",
    "            print(f\"Conclusion: No significant correlation found (p >= {alpha_corr}). Fail to reject H₀.\")\n",
    "        \n",
    "        # Correlation 2: Efficiency vs. Subjective Quality\n",
    "        print(f\"\\nCorrelation: Sleep Efficiency vs. Self-reported Quality\")\n",
    "        rho_eff, p_eff = stats.spearmanr(corr_df_cleaned['Sleep Efficiency'], corr_df_cleaned['Self-reported Sleep Quality (1-10)'], nan_policy='omit')\n",
    "        print(f\"Spearman's rho: {rho_eff:.3f}\")\n",
    "        print(f\"P-value: {p_eff:.4f}\")\n",
    "        if p_eff < alpha_corr:\n",
    "            print(f\"Conclusion: Significant correlation found (p < {alpha_corr}). Reject H₀.\")\n",
    "        else:\n",
    "            print(f\"Conclusion: No significant correlation found (p >= {alpha_corr}). Fail to reject H₀.\")\n",
    "\n",
    "# --- Visualization for Correlation Variables (Saving happens outside the redirect_stdout context) ---\n",
    "print(\"\\n--- Generating and Saving Plots for Section 4 ---\")\n",
    "if len(corr_df_cleaned) >= 3:\n",
    "    fig_hist, axes_hist = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    sns.histplot(corr_df_cleaned['Sleep Latency (m)'], kde=True, ax=axes_hist[0])\n",
    "    axes_hist[0].set_title('Distribution of Sleep Latency (m)')\n",
    "    sns.histplot(corr_df_cleaned['Sleep Efficiency'], kde=True, ax=axes_hist[1])\n",
    "    axes_hist[1].set_title('Distribution of Sleep Efficiency (%)')\n",
    "    sns.histplot(corr_df_cleaned['Self-reported Sleep Quality (1-10)'], kde=False, discrete=True, ax=axes_hist[2])\n",
    "    axes_hist[2].set_title('Distribution of Self-reported Quality')\n",
    "    fig_hist.suptitle('Distributions of Variables Used in Correlation Analysis (Per-Night Data)', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    hist_filename = os.path.join(figures_dir, 'histograms_correlation_variables.png')\n",
    "    fig_hist.savefig(hist_filename, bbox_inches='tight')\n",
    "    plt.close(fig_hist) # Close the figure\n",
    "    print(f\"Saved histogram plot to: {hist_filename}\")\n",
    "else:\n",
    "    print(\"Skipping histogram generation due to insufficient data.\")\n",
    "\n",
    "print(f\"Section 4 processing complete. Results appended to {output_txt_file}\")\n",
    "print(\"\\n--- Analysis Finished --- \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
